{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 定义一个简单的计算图\n",
    "input1 = tf.constant([1.0, 2.0, 3.0], name='input_one')\n",
    "input2 = tf.Variable(tf.random_uniform([3]), name='input_two')\n",
    "output = tf.add_n([input1, input2], name='add')\n",
    "\n",
    "# 生成一个写日志的writer，并将当前计算图写入日志\n",
    "writer = tf.summary.FileWriter('log/test', tf.get_default_graph())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### TensorFlow 计算图可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf计算图中同一个命名空间下的所有结点会缩略成一个结点，如tr.variable_scope()\n",
    "import tensorflow as tf\n",
    "\n",
    "#将输入定义放入各自的命名空间，TensorBoard才能根据命名空间整理计算图上的结点\n",
    "with tf.variable_scope('input_1'):\n",
    "    input1 = tf.constant([1.0, 2.0, 3.0], name='input_one')\n",
    "#下面的运算与结点都会收缩到input_2结点中\n",
    "with tf.variable_scope('input_2'):\n",
    "    input2_1 = tf.Variable(tf.random_uniform([3]), name='input_two')\n",
    "    input2 = tf.multiply(input2_1, 3.0, name='multiply')\n",
    "output = tf.add_n([input1, input2], name='add')\n",
    "writer = tf.summary.FileWriter('log/test', tf.get_default_graph())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 监控指标可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将TensorFlow程序运行时的信息输出到TensorBoard日志文件中\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "summary_dir = 'log/test'\n",
    "batch_size = 100\n",
    "train_steps = 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成变量监控信息并定义生成监控信息日志的操作，var给出了需要记录的张量，name给出了在可视化结果中显示的图表名称\n",
    "\n",
    "def variable_summaries(var, name):\n",
    "    # 将生成监控信息的操作放在同一命名空间下\n",
    "    with tf.name_scope('summaries'):\n",
    "        # 记录张量的取值分布。给定图表名和张量，tf.histogram_summary函数会生成一个summary protocool buffer\n",
    "        # 将Summary写入TensorBoard日志文件后，HISTOGRAPH栏下可看到对应名称的图表。\n",
    "        tf.summary.histogram(name, var)\n",
    "\n",
    "        # 定义生成平均值信息日志的操作。记录变量均值信息的日志标签名为“mean/”+name，其中mean为命名空间。\n",
    "        # 相同命名空间中的指标会被整合到同一栏，name给出了当前监控指标属于哪一个变量\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean/'+name, mean)\n",
    "        # 计算变量的标准差，并定义生成其日志的操作\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev/'+name, stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义一层全连接网络\n",
    "def nn_layer(input_tensor, input_dim, output_dim, layer_name, act=tf.nn.relu):\n",
    "    # 将同一层神经网络放在统一的命名空间下\n",
    "    with tf.name_scope(layer_name):\n",
    "        # 声明神经网络的权重，并调用生成权重监控信息日志的函数\n",
    "        with tf.name_scope('weights'):\n",
    "            weights = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1))\n",
    "            variable_summaries(weights, layer_name+'/weights')\n",
    "\n",
    "        # 声明神经网络的偏置项，并调用生成偏置项监控信息日志的函数\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[output_dim]))\n",
    "            variable_summaries(biases, layer_name+'/biases')\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            preactivate = tf.matmul(input_tensor, weights)+biases\n",
    "            # 记录神经网络输出结点在馈送到激活函数前的分布\n",
    "            tf.summary.histogram(layer_name+'/pre_activations', preactivate)\n",
    "        activations = act(preactivate, name='activations')\n",
    "        # 记录输出结点经激活函数后的分布\n",
    "        tf.summary.histogram(layer_name+'activations', activations)\n",
    "        return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    mnist = input_data.read_data_sets('data/MNIST', one_hot=True)\n",
    "    # 定义输入\n",
    "    with tf.name_scope('input'):\n",
    "        x = tf.placeholder(tf.float32, [None, 784], name='x_input')\n",
    "        y = tf.placeholder(tf.float32, [None, 10], name='y_output')\n",
    "\n",
    "    # 将输入向量还原为像素矩阵，并将图片信息写入日志\n",
    "    with tf.name_scope('input_reshape'):\n",
    "        image_shaped_input = tf.reshape(x, [-1, 28, 28, 1])\n",
    "        tf.summary.image('input', image_shaped_input, 10)\n",
    "\n",
    "    hidden1 = nn_layer(x, 784, 500, 'layer1')\n",
    "    y_hat = nn_layer(hidden1, 500, 10, 'layer2', act=tf.identity)\n",
    "\n",
    "    # 计算交叉熵并生成交叉熵的监控日志\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_hat, labels=y))\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "    # 计算模型在当前给定数据集上的正确率，并生成监控日志\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_hat, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "    # merge_all函数会整理所有的日志生成操作，Session中运行一次就相当于将所有日志生成操作运行一次写入文件\n",
    "    merged = tf.summary.merge_all()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter(summary_dir, sess.graph)\n",
    "        tf.global_variables_initializer().run()\n",
    "\n",
    "        for i in range(train_steps):\n",
    "            xs, ys = mnist.train.next_batch(batch_size)\n",
    "            # 运行训练步骤以及所有的日志生成操作，得到这次运行的日志。\n",
    "            summary, _ = sess.run([merged, train_step], feed_dict={x: xs, y: ys})\n",
    "            # 将得到的所有日志写入日志文件，这样TensorBoard程序就可以拿到这次运行所对应的运行信息。\n",
    "            summary_writer.add_summary(summary, i)\n",
    "            if i % 1000 == 0:\n",
    "                validation_acc = sess.run(accuracy, feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "                print((\"After %d training steps, validation accuracy is %g\" %(i, validation_acc)))\n",
    "    summary_writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
